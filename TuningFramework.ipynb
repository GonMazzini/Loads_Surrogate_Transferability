{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GonMazzini/Loads_Surrogate_Transferability/blob/main/TuningFramework.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9P0l_d61zRnQ"
      },
      "source": [
        "Thits notebook is the MASTER notebook for running hyper-parameter tuning.\n",
        "\n",
        "\n",
        "> Section 1\n",
        "\n",
        "\n",
        "1.   Read data\n",
        "2.   Train-Val-Test split\n",
        "3.   Scale data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "l9b4V5nszS9-",
        "outputId": "5d8c7a62-5967-44c5-86fb-ef0d3eb662cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting parameter-sherpa\n",
            "  Downloading parameter-sherpa-1.0.6.tar.gz (513 kB)\n",
            "\u001b[?25l\r\u001b[K     |▋                               | 10 kB 19.7 MB/s eta 0:00:01\r\u001b[K     |█▎                              | 20 kB 15.2 MB/s eta 0:00:01\r\u001b[K     |██                              | 30 kB 7.5 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 40 kB 6.7 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 51 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |███▉                            | 61 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████▌                           | 71 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |█████                           | 81 kB 4.8 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 92 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 102 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████                         | 112 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 122 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 133 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 143 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 153 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 163 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████▉                     | 174 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 184 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 194 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 204 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 215 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 225 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 235 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 245 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 256 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████▋               | 266 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 276 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 286 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 296 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 307 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▉            | 317 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 327 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 337 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 348 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 358 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 368 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 378 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 389 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 399 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 409 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 419 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 430 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 440 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 450 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 460 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 471 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 481 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 491 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 501 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 512 kB 4.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 513 kB 4.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.20.3 in /usr/local/lib/python3.7/dist-packages (from parameter-sherpa) (1.3.5)\n",
            "Requirement already satisfied: pymongo>=3.5.1 in /usr/local/lib/python3.7/dist-packages (from parameter-sherpa) (4.0.2)\n",
            "Requirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from parameter-sherpa) (1.21.5)\n",
            "Requirement already satisfied: scipy>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from parameter-sherpa) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from parameter-sherpa) (1.0.2)\n",
            "Requirement already satisfied: flask>=0.12.2 in /usr/local/lib/python3.7/dist-packages (from parameter-sherpa) (1.1.4)\n",
            "Collecting GPyOpt>=1.2.5\n",
            "  Downloading GPyOpt-1.2.6.tar.gz (56 kB)\n",
            "\u001b[K     |████████████████████████████████| 56 kB 4.9 MB/s \n",
            "\u001b[?25hCollecting enum34\n",
            "  Downloading enum34-1.1.10-py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from parameter-sherpa) (3.2.2)\n",
            "Requirement already satisfied: click<8.0,>=5.1 in /usr/local/lib/python3.7/dist-packages (from flask>=0.12.2->parameter-sherpa) (7.1.2)\n",
            "Requirement already satisfied: Werkzeug<2.0,>=0.15 in /usr/local/lib/python3.7/dist-packages (from flask>=0.12.2->parameter-sherpa) (1.0.1)\n",
            "Requirement already satisfied: itsdangerous<2.0,>=0.24 in /usr/local/lib/python3.7/dist-packages (from flask>=0.12.2->parameter-sherpa) (1.1.0)\n",
            "Requirement already satisfied: Jinja2<3.0,>=2.10.1 in /usr/local/lib/python3.7/dist-packages (from flask>=0.12.2->parameter-sherpa) (2.11.3)\n",
            "Collecting GPy>=1.8\n",
            "  Downloading GPy-1.10.0.tar.gz (959 kB)\n",
            "\u001b[K     |████████████████████████████████| 959 kB 38.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from GPy>=1.8->GPyOpt>=1.2.5->parameter-sherpa) (1.15.0)\n",
            "Collecting paramz>=0.9.0\n",
            "  Downloading paramz-0.9.5.tar.gz (71 kB)\n",
            "\u001b[K     |████████████████████████████████| 71 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cython>=0.29 in /usr/local/lib/python3.7/dist-packages (from GPy>=1.8->GPyOpt>=1.2.5->parameter-sherpa) (0.29.28)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2<3.0,>=2.10.1->flask>=0.12.2->parameter-sherpa) (2.0.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->parameter-sherpa) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.20.3->parameter-sherpa) (2018.9)\n",
            "Requirement already satisfied: decorator>=4.0.10 in /usr/local/lib/python3.7/dist-packages (from paramz>=0.9.0->GPy>=1.8->GPyOpt>=1.2.5->parameter-sherpa) (4.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->parameter-sherpa) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->parameter-sherpa) (1.1.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->parameter-sherpa) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->parameter-sherpa) (0.11.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->parameter-sherpa) (3.0.7)\n",
            "Building wheels for collected packages: parameter-sherpa, GPyOpt, GPy, paramz\n",
            "  Building wheel for parameter-sherpa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for parameter-sherpa: filename=parameter_sherpa-1.0.6-py2.py3-none-any.whl size=542134 sha256=27e83c8c83e01c6f208700a60a427bd5d062abdd736964a8ea20757714589811\n",
            "  Stored in directory: /root/.cache/pip/wheels/96/d9/cb/99569566e5e9b3ef0265ba4cbce3ff16f7692988833aa942f5\n",
            "  Building wheel for GPyOpt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPyOpt: filename=GPyOpt-1.2.6-py3-none-any.whl size=83609 sha256=a2c2943b9350f03553aeb9f5b775151da6384eaddc82a0b82aa93ac9f3049c00\n",
            "  Stored in directory: /root/.cache/pip/wheels/e6/fa/d1/f9652b5af79f769a0ab74dbead7c7aea9a93c6bc74543fd3ec\n",
            "  Building wheel for GPy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPy: filename=GPy-1.10.0-cp37-cp37m-linux_x86_64.whl size=2565060 sha256=191ece610447eb0ebbaa431f3a2ab45da91ec5e01fcfb0bd49a7b22e79bab7d9\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/18/28/dd1ce0192a81b71a3b086fd952511d088b21e8359ea496860a\n",
            "  Building wheel for paramz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for paramz: filename=paramz-0.9.5-py3-none-any.whl size=102566 sha256=2757ac403f5c0b7bc82587848d868a4fd018254bca4064a8248955f224f81c5b\n",
            "  Stored in directory: /root/.cache/pip/wheels/c8/95/f5/ce28482da28162e6028c4b3a32c41d147395825b3cd62bc810\n",
            "Successfully built parameter-sherpa GPyOpt GPy paramz\n",
            "Installing collected packages: paramz, GPy, GPyOpt, enum34, parameter-sherpa\n",
            "Successfully installed GPy-1.10.0 GPyOpt-1.2.6 enum34-1.1.10 parameter-sherpa-1.0.6 paramz-0.9.5\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "enum"
                ]
              }
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install parameter-sherpa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Q2oZpZQIzoQT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d513ecaf-71c8-4d1d-b539-17f32ab6a5f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n"
          ]
        }
      ],
      "source": [
        "# Import all required libraries\n",
        "\n",
        "from __future__ import print_function\n",
        "import sherpa\n",
        "from sherpa.algorithms import Genetic\n",
        "import time\n",
        "import pandas as pd \n",
        "import numpy as np\n",
        "import math\n",
        "from random import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nF2rjMCtzRnU"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "# Section 1:\n",
        "\n",
        "Section 1.1: Read data\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 194
        },
        "id": "W1kffmHZzRnV",
        "outputId": "8701686c-9c53-4480-b097-843d9ffc91c7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  pointno          U    SigmaU     Alpha      MannL  MannGamma  \\\n",
              "0           0        1   4.000000  0.100000 -0.650000   7.500000   1.000000   \n",
              "1           1        2  10.150758  1.208656 -0.139692  48.470634   1.363636   \n",
              "\n",
              "   VeerDeltaPhi    TT_Mx_avg   TT_My_avg     TB_Mx_avg    TB_My_avg  \\\n",
              "0    -22.250000   747.561872  200.666288   6708.717789  8861.885588   \n",
              "1     -4.771217  3556.031457  676.339081  16692.647572  6329.099515   \n",
              "\n",
              "     TT_Mz_avg    MS_Mz_avg     BR_Mx_avg     BR_My_avg  \n",
              "0   819.209904    63.457528   4253.317748  15006.726860  \n",
              "1  3746.460605  1354.995442  10409.290476  16289.414152  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3c03f2d5-f2fc-4819-af7c-c8eefe62b8dd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>pointno</th>\n",
              "      <th>U</th>\n",
              "      <th>SigmaU</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>MannL</th>\n",
              "      <th>MannGamma</th>\n",
              "      <th>VeerDeltaPhi</th>\n",
              "      <th>TT_Mx_avg</th>\n",
              "      <th>TT_My_avg</th>\n",
              "      <th>TB_Mx_avg</th>\n",
              "      <th>TB_My_avg</th>\n",
              "      <th>TT_Mz_avg</th>\n",
              "      <th>MS_Mz_avg</th>\n",
              "      <th>BR_Mx_avg</th>\n",
              "      <th>BR_My_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>-0.650000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-22.250000</td>\n",
              "      <td>747.561872</td>\n",
              "      <td>200.666288</td>\n",
              "      <td>6708.717789</td>\n",
              "      <td>8861.885588</td>\n",
              "      <td>819.209904</td>\n",
              "      <td>63.457528</td>\n",
              "      <td>4253.317748</td>\n",
              "      <td>15006.726860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10.150758</td>\n",
              "      <td>1.208656</td>\n",
              "      <td>-0.139692</td>\n",
              "      <td>48.470634</td>\n",
              "      <td>1.363636</td>\n",
              "      <td>-4.771217</td>\n",
              "      <td>3556.031457</td>\n",
              "      <td>676.339081</td>\n",
              "      <td>16692.647572</td>\n",
              "      <td>6329.099515</td>\n",
              "      <td>3746.460605</td>\n",
              "      <td>1354.995442</td>\n",
              "      <td>10409.290476</td>\n",
              "      <td>16289.414152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c03f2d5-f2fc-4819-af7c-c8eefe62b8dd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c03f2d5-f2fc-4819-af7c-c8eefe62b8dd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c03f2d5-f2fc-4819-af7c-c8eefe62b8dd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "df = pd.read_excel('LoadsDataBase_6D_Set123_FiltMinMaxCrit.xlsx') # Average the values from Set1,Set2 and Set3.\n",
        "df.head(2)\n",
        "# 0 : TT_Mx_avg# 1 : TT_My_avg# 2 : TB_Mx_avg# 3 : TB_My_avg# 4 : MS_Mz_avg# 5 : BR_Mx_avg# 6 : BR_My_avg# 7 : TT-Mz_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Section 1.2: Train-Val-Test split."
      ],
      "metadata": {
        "id": "whDMqYOyKsWS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "gTxt7cZJzRnV"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:,2:8]\n",
        "y = df.iloc[:,8:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eX_LPh9wzRnW",
        "outputId": "622cecbb-9c6e-4aee-9ab1-d517c07d374d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The filtered data set consits on: 7664 entries.\n",
            "A total of 6131 will be used for training and validation.\n",
            "A total of 1533 will be used for testing the final model.\n"
          ]
        }
      ],
      "source": [
        "# Test split:\n",
        "X, X_test, y, y_test = train_test_split(X,y, test_size = 0.2, shuffle = True,  random_state = 101)\n",
        "\n",
        "print(f'The filtered data set consits on: {len(df)} entries.')\n",
        "print(f'A total of {len(X)} will be used for training and validation.')\n",
        "print(f'A total of {len(X_test)} will be used for testing the final model.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6sjTHp4zRnW"
      },
      "source": [
        "---\n",
        "Section 1.3: Feature scaling"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "4nBJ9T1TzRnW"
      },
      "outputs": [],
      "source": [
        "feature_range = (0, 1)\n",
        "scaler_x = preprocessing.MinMaxScaler(feature_range=feature_range).fit(X)\n",
        "X_scaled = scaler_x.transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fp5EhbtozRnW"
      },
      "source": [
        "### Separte between train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_kR4yaL0zRnX"
      },
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled,y.values, test_size = 0.2, shuffle = True,  random_state = 101)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ezp2exU1NR36",
        "outputId": "4b471ab5-da66-4a6a-93c9-eb4802cfabf3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A total of 4904 for training, 64.0 % of total data\n",
            "A total of 1227 for validation, 16.0 % of total data\n",
            "A total of 1533 for testing, 20.0 % of total data\n"
          ]
        }
      ],
      "source": [
        "# printing number of samples for train-validation-test\n",
        "print(f'A total of {y_train.shape[0]} for training, {round(100*y_train.shape[0]/len(df),1)} % of total data')\n",
        "print(f'A total of {y_val.shape[0]} for validation, {round(100*y_val.shape[0]/len(df),1)} % of total data')\n",
        "print(f'A total of {y_test.shape[0]} for testing, {round(100*y_test.shape[0]/len(df),1)} % of total data')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "# Section 2: Model Selection\n",
        "\n",
        "\n",
        "\n",
        "> Select the model according to the hyper-parameter to be tuned. The following classes are available:\n",
        "\n",
        "\n",
        "\n",
        ">> *BaseModel* (**same hidden units per layer**)\n",
        "\n",
        "\n",
        "*   2 hidden layers with same number of hidden units.\n",
        "*   Weights initialized with Normal Kaimin (=He)\n",
        "*   ReLu act_fn\n",
        "\n",
        ">> *VariableLayers* (**just for number of hidden units**)\n",
        "\n",
        "\n",
        "*   Variable number of Hidden Layers\n",
        "*   Weights initialized with Normal Kaimin (=He)\n",
        "*   ReLu act_fn\n",
        "\n",
        ">> *VariableUnits* (**different units per layer**)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Bb7kqq74LuI_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hVfzqEXbzRnX"
      },
      "outputs": [],
      "source": [
        "input_size = 6             # np.shape(X_train)[1]\n",
        "output_channels = 8        # np.shape(y_train)[1]\n",
        "hidden_size = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "hEj_xF9pzRnX"
      },
      "outputs": [],
      "source": [
        "class BaseModel(nn.Module):\n",
        "    \n",
        "    def __init__(self, hidden_size):   \n",
        "        super(BaseModel,self).__init__()  # inherit from the superclass Module\n",
        "        self.hidden_size = hidden_size\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features= input_size,\n",
        "                             out_features= self.hidden_size,                             \n",
        "                            bias = True)  \n",
        "        nn.init.kaiming_normal_(self.fc1.weight)\n",
        "\n",
        "        self.fc2 = nn.Linear(in_features = self.hidden_size, \n",
        "                             out_features = self.hidden_size,\n",
        "                            bias = True)\n",
        "        nn.init.kaiming_normal_(self.fc1.weight)\n",
        "\n",
        "        self.fc3 = nn.Linear(in_features = self.hidden_size, \n",
        "                             out_features = output_channels,\n",
        "                            bias = True)\n",
        "        nn.init.kaiming_normal_(self.fc1.weight)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        \n",
        "        out = self.fc1(x)  \n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc3(out)                       #  torch.tanh(self.fc3(out))\n",
        "        \n",
        "        return out  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO :: Add HE intializing (how to acces each module?)\n",
        "\n",
        "class VariableLayers(nn.Module):\n",
        "\n",
        "    \"\"\" A feedforward network designed for tuning number of layers and hidden units.\n",
        "    By @GonMazzini\"\"\"\n",
        "\n",
        "    def __init__(self, input_dim, output_dim, n_hidLayers, hidden_size):\n",
        "        super(VariableLayers, self).__init__()\n",
        "        self.input_dim = input_dim\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_size = hidden_size\n",
        "        self.n_hidLayers = n_hidLayers\n",
        "        current_dim = input_dim\n",
        "        self.layers = nn.ModuleList()\n",
        "        \n",
        "        for hdim in [self.hidden_size]*self.n_hidLayers:\n",
        "            self.layers.append(nn.Linear(current_dim, hdim))\n",
        "            current_dim = hdim\n",
        "        self.layers.append(nn.Linear(current_dim, output_dim))\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers[:-1]:\n",
        "            x = F.relu(layer(x))\n",
        "        out = F.relu(self.layers[-1](x))\n",
        "        return out "
      ],
      "metadata": {
        "id": "ozA9yvk2MWuP"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class VariableUnits(nn.Module):\n",
        "\n",
        "  def __init__(self, hidden_size1, hidden_size2):\n",
        "    super(VariableUnits, self).__init__()\n",
        "    self.hidden_size1 = hidden_size1\n",
        "    self.hidden_size2 = hidden_size2\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features = input_size,\n",
        "                         out_features = self.hidden_size1,\n",
        "                         bias = True)\n",
        "    nn.init.kaiming_normal_(self.fc1.weight)\n",
        "\n",
        "    self.fc2 = nn.Linear(in_features = self.hidden_size1,\n",
        "                         out_features = self.hidden_size2,\n",
        "                         bias = True)\n",
        "    \n",
        "    nn.init.kaiming_normal_(self.fc2.weight)\n",
        "\n",
        "    self.fc3 = nn.Linear(in_features = self.hidden_size2,\n",
        "                      out_features = output_channels,\n",
        "                      bias = True)\n",
        "\n",
        "    nn.init.kaiming_normal_(self.fc3.weight)\n",
        "\n",
        "  def forward(self,x):\n",
        "        \n",
        "    out = self.fc1(x)  \n",
        "    out = F.relu(out)\n",
        "    out = self.fc2(out)\n",
        "    out = F.relu(out)\n",
        "    out = self.fc3(out)                       #  torch.tanh(self.fc3(out))\n",
        "    \n",
        "    return out  "
      ],
      "metadata": {
        "id": "Rzreeb4EclUQ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xO8OBaiRzRnY"
      },
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "# Section 3: DataLoader \n",
        "\n",
        "\n",
        ">  Use the PyTorch DataLoader and Dataset utils.\n",
        "\n",
        "- DataLoader class combines a dataset and a sampler, and provides an iterable over the given dataset for training the model\n",
        "- Dataset: just an abstract class representing a :class:`Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "guVFdZgMzRnY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "54ea432e-3616-405d-9a4a-11d289f8257c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9213, 0.5395, 0.2971, 0.1574, 0.7369, 0.3075], dtype=torch.float64) tensor([ 7116.1376,   808.7441, 21966.9989, 16383.7768,  7347.3186,   807.4632,\n",
            "        18567.6736, 16935.8620], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "class FatigueLoads_TrainSet(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = X_train.shape[0]\n",
        "        self.x_data = torch.from_numpy(X_train) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(y_train) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "    \n",
        "class FatigueLoads_ValidationSet(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = X_val.shape[0]\n",
        "        self.x_data = torch.from_numpy(X_val) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(y_val) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "\n",
        "train_dataset = FatigueLoads_TrainSet()\n",
        "valid_dataset = FatigueLoads_ValidationSet()\n",
        "\n",
        "### Get first sample and unpack. \n",
        "# Note that the enviromental inputs are normalized using MinMaxScaler\n",
        "\n",
        "first_data = train_dataset[0]\n",
        "features, loads = first_data\n",
        "print(features, loads)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "# Section 4: Select algorithm and parameters.\n",
        "\n",
        "> Options\n",
        "\n",
        "\n",
        "1.   RandomSearch  :  [ lr , hu1   , hu2 ] \n",
        "2.   RandomSearch  :  [ lr ,n_lays , hu12 ]\n",
        "3.   GridSearch    : \n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "-MYbe-sApQ4U"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "5KXldvsU08MV"
      },
      "outputs": [],
      "source": [
        "# Option 1:RandomSearch\n",
        "# To be used with Model \"VariableUnits\"\n",
        "algorithm = sherpa.algorithms.RandomSearch(max_num_trials = 32)\n",
        "parameters = [sherpa.Ordinal('hidden_size1', [10,25,50,100]),\n",
        "              sherpa.Ordinal('hidden_size2', [10,25,50,100]),\n",
        "              sherpa.Ordinal('lr',[0.001,0.005,0.01,0.05,0.1])]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "fXK9eWS81rHZ"
      },
      "outputs": [],
      "source": [
        "# Option 2: RandomSearch\n",
        "# To be used with \"VariableLayers\" \n",
        "# TODO\n",
        "algorithm = sherpa.algorithms.GridSearch(num_grid_points=3)\n",
        "parameters = [sherpa.Discrete('n_hidLayers', [2, 4]),\n",
        "              sherpa.Discrete('hidden_size', [16, 64])]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 3: GridSearch\n",
        "# To be used with \"VariableLayers"
      ],
      "metadata": {
        "id": "Zbpn8YLK1geD"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Option 4: Bayesian Optimization\n",
        "# TODO"
      ],
      "metadata": {
        "id": "5m1lOVal1oW_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "# Section 5: Define the training parameters and sherpa study."
      ],
      "metadata": {
        "id": "SkRQqeK42zXV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "323d_UnszRnZ"
      },
      "outputs": [],
      "source": [
        "loss = nn.MSELoss()\n",
        "\n",
        "# list to store results\n",
        "train_losses , val_losses= [],[]\n",
        "\n",
        "batch_size = 128\n",
        "num_epochs = 3\n",
        "\n",
        "num_batches_train = X_train.shape[0] // batch_size\n",
        "num_batches_test = X_val.shape[0] // batch_size\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "study = sherpa.Study(parameters= parameters,\n",
        "                     algorithm=  algorithm,\n",
        "                     lower_is_better=True)"
      ],
      "metadata": {
        "id": "0wS9Tj3e5QK1",
        "outputId": "55d6a2f9-b750-4c4b-e32b-80b57b820c6c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:sherpa.core:\n",
            "-------------------------------------------------------\n",
            "SHERPA Dashboard running. Access via\n",
            "http://172.28.0.2:8884 if on a cluster or\n",
            "http://localhost:8884 if running locally.\n",
            "-------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " * Serving Flask app \"sherpa.app.app\" (lazy loading)\n",
            " * Environment: production\n",
            "\u001b[31m   WARNING: This is a development server. Do not use it in a production deployment.\u001b[0m\n",
            "\u001b[2m   Use a production WSGI server instead.\u001b[0m\n",
            " * Debug mode: on\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "---\n",
        "---\n",
        "---\n",
        "# Section 6: Select number of models to train for each paramter configuration. \n",
        "\n",
        "# TODO: add to.(device) to enable GPU.\n",
        "\n",
        "1.   Use first case for training just one model.\n",
        "2.   Use second case for training 3 models. \n",
        "3.   Add checkpoints to save results as df. \n",
        "\n"
      ],
      "metadata": {
        "id": "mBSxIhbW-au_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GnOKI0762M9u"
      },
      "outputs": [],
      "source": [
        "# 1: To be used when Model = VariableUnits.\n",
        "# Just one model trained.\n",
        "for trial in study:\n",
        "\n",
        "  print(\"Trial {}:\\t{}\".format(trial.id, trial.parameters))\n",
        "  model = VariableUnits(trial.parameters['hidden_size1'],\n",
        "                        trial.parameters['hidden_size2'])\n",
        "  \n",
        "  optimizer = optim.Adam(model.parameters(), lr = trial.parameters['lr'])\n",
        "  \n",
        "  for epoch in range(num_epochs):\n",
        "    \n",
        "    model.train()\n",
        "    \n",
        "    for i, (inputs, loads) in enumerate(train_loader):\n",
        "        #print(features, loads)\n",
        "        \n",
        "        optimizer.zero_grad()                      # zeroize accumulated gradients in parameters             \n",
        "        \n",
        "        output = model(inputs.float())             # forwards pass       \n",
        "        batch_loss = loss(output, loads.float())   # compute loss for current batch\n",
        "        \n",
        "        batch_loss.backward()                      # compute the gradient of the loss wrt. model parameters\n",
        "        optimizer.step()                           # update weights according to the comptued gradients\n",
        "        \n",
        "    \n",
        "    epoch_loss_train = 0\n",
        "    epoch_loss_test = 0\n",
        "    model.eval()\n",
        "    \n",
        "    ##### Evaluate training\n",
        "    for i, (inputs, loads) in enumerate(train_loader):\n",
        "        \n",
        "        output = model(inputs.float())\n",
        "        \n",
        "        batch_loss_train = loss(output, loads.float())  # compute loss for the current batch\n",
        "        epoch_loss_train += batch_loss_train            # accumulate loss for the current epoch\n",
        "        \n",
        "        #print(f'Epoch: {epoch+1}/{num_epochs}  | Step {i+1}/{n_iterations}')\n",
        "    \n",
        "    ##### Evaluate validation    \n",
        "    for i, (inputs, loads) in enumerate(valid_loader):\n",
        "        \n",
        "        output = model(inputs.float())\n",
        "        \n",
        "        batch_loss_test = loss(output, loads.float())  # compute loss for the current batch\n",
        "        epoch_loss_test += batch_loss_test     # accumulate loss for the current epoch\n",
        "        \n",
        "        #print(f'Epoch: {epoch+1}/{num_epochs}  | Step {i+1}/{n_iterations}')\n",
        "    \n",
        "    if epoch % 1 == 0: \n",
        "        print(f'Epoch: {epoch+1}/{num_epochs} | Train loss: {epoch_loss_train/num_batches_train}       | Val loss {epoch_loss_test/num_batches_test}')\n",
        "\n",
        "        study.add_observation(trial=trial,\n",
        "                              iteration=epoch,\n",
        "                              objective=epoch_loss_test.detach().numpy())\n",
        "    \n",
        "    if study.should_trial_stop(trial):\n",
        "        break \n",
        "    # store in list for plotting the loss per epoch    \n",
        "    val_losses.append(epoch_loss_test/num_batches_test)  \n",
        "    train_losses.append(epoch_loss_train/num_batches_train)  \n",
        "  #study.finalize(trial)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "z_uF07KUG5uX",
        "outputId": "2b24bf6a-200c-4a76-9b03-1c476df4528a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    Trial-ID        Status  Iteration  hidden_size1  hidden_size2     lr  \\\n",
              "0          1  INTERMEDIATE          0           100            10  0.100   \n",
              "1          1  INTERMEDIATE          1           100            10  0.100   \n",
              "2          1  INTERMEDIATE          2           100            10  0.100   \n",
              "3          2  INTERMEDIATE          0            10            50  0.050   \n",
              "4          2  INTERMEDIATE          1            10            50  0.050   \n",
              "..       ...           ...        ...           ...           ...    ...   \n",
              "91        31  INTERMEDIATE          1            50            50  0.005   \n",
              "92        31  INTERMEDIATE          2            50            50  0.005   \n",
              "93        32  INTERMEDIATE          0           100            10  0.010   \n",
              "94        32  INTERMEDIATE          1           100            10  0.010   \n",
              "95        32  INTERMEDIATE          2           100            10  0.010   \n",
              "\n",
              "       Objective  \n",
              "0    349758000.0  \n",
              "1    236138190.0  \n",
              "2    179342300.0  \n",
              "3    761814500.0  \n",
              "4    291997250.0  \n",
              "..           ...  \n",
              "91  1699453200.0  \n",
              "92  1233039500.0  \n",
              "93  1823856400.0  \n",
              "94  1384841200.0  \n",
              "95   551835840.0  \n",
              "\n",
              "[96 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8d3c232d-0d34-451d-a4b1-fbf933692c2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Trial-ID</th>\n",
              "      <th>Status</th>\n",
              "      <th>Iteration</th>\n",
              "      <th>hidden_size1</th>\n",
              "      <th>hidden_size2</th>\n",
              "      <th>lr</th>\n",
              "      <th>Objective</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>0.100</td>\n",
              "      <td>349758000.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>0.100</td>\n",
              "      <td>236138190.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>0.100</td>\n",
              "      <td>179342300.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>0</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0.050</td>\n",
              "      <td>761814500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>1</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0.050</td>\n",
              "      <td>291997250.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>31</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>1</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>0.005</td>\n",
              "      <td>1699453200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>31</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>2</td>\n",
              "      <td>50</td>\n",
              "      <td>50</td>\n",
              "      <td>0.005</td>\n",
              "      <td>1233039500.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>32</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>1823856400.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>32</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>1</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>1384841200.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>32</td>\n",
              "      <td>INTERMEDIATE</td>\n",
              "      <td>2</td>\n",
              "      <td>100</td>\n",
              "      <td>10</td>\n",
              "      <td>0.010</td>\n",
              "      <td>551835840.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>96 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8d3c232d-0d34-451d-a4b1-fbf933692c2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8d3c232d-0d34-451d-a4b1-fbf933692c2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8d3c232d-0d34-451d-a4b1-fbf933692c2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ],
      "source": [
        "study.results"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "g6lcj4lLzRnb"
      ],
      "name": "PyTorch_Model_v4_Sherpa.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}