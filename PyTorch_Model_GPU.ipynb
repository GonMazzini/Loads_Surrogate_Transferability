{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GonMazzini/Loads_Surrogate_Transferability/blob/main/PyTorch_Model_GPU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZTT04AOiyfp4"
      },
      "source": [
        "% Saved 5/3/2022    13:25\n",
        "- Try outputs e inputs with different scaler?\n",
        "- Add one more layer?\n",
        "- Add cuda to run in collab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "pUp9ZRHgyfp8"
      },
      "outputs": [],
      "source": [
        "import pandas as pd \n",
        "import numpy as np\n",
        "import math\n",
        "from random import shuffle\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iICk0zpByfp-",
        "outputId": "3e0c8bc4-baf1-4a47-cb01-d02dec32e54d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU\n"
          ]
        }
      ],
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"CPU\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRiA-vLbyfp_"
      },
      "source": [
        "# 0- Read the data as a data frame"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "Yt3GnH6VyfqA",
        "outputId": "34d75f30-109b-4fe6-b71f-14936fc8f167"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-c08458c1-2973-48de-899e-5a0239da4954\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>pointno</th>\n",
              "      <th>U</th>\n",
              "      <th>SigmaU</th>\n",
              "      <th>Alpha</th>\n",
              "      <th>MannL</th>\n",
              "      <th>MannGamma</th>\n",
              "      <th>VeerDeltaPhi</th>\n",
              "      <th>TT_Mx_avg</th>\n",
              "      <th>TT_My_avg</th>\n",
              "      <th>TB_Mx_avg</th>\n",
              "      <th>TB_My_avg</th>\n",
              "      <th>TT_Mz_avg</th>\n",
              "      <th>MS_Mz_avg</th>\n",
              "      <th>BR_Mx_avg</th>\n",
              "      <th>BR_My_avg</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4.000000</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>-0.650000</td>\n",
              "      <td>7.500000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>-22.250000</td>\n",
              "      <td>747.561872</td>\n",
              "      <td>200.666288</td>\n",
              "      <td>6708.717789</td>\n",
              "      <td>8861.885588</td>\n",
              "      <td>819.209904</td>\n",
              "      <td>63.457528</td>\n",
              "      <td>4253.317748</td>\n",
              "      <td>15006.726860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>10.150758</td>\n",
              "      <td>1.208656</td>\n",
              "      <td>-0.139692</td>\n",
              "      <td>48.470634</td>\n",
              "      <td>1.363636</td>\n",
              "      <td>-4.771217</td>\n",
              "      <td>3556.031457</td>\n",
              "      <td>676.339081</td>\n",
              "      <td>16692.647572</td>\n",
              "      <td>6329.099515</td>\n",
              "      <td>3746.460605</td>\n",
              "      <td>1354.995442</td>\n",
              "      <td>10409.290476</td>\n",
              "      <td>16289.414152</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c08458c1-2973-48de-899e-5a0239da4954')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c08458c1-2973-48de-899e-5a0239da4954 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c08458c1-2973-48de-899e-5a0239da4954');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Unnamed: 0  pointno          U    SigmaU     Alpha      MannL  MannGamma  \\\n",
              "0           0        1   4.000000  0.100000 -0.650000   7.500000   1.000000   \n",
              "1           1        2  10.150758  1.208656 -0.139692  48.470634   1.363636   \n",
              "\n",
              "   VeerDeltaPhi    TT_Mx_avg   TT_My_avg     TB_Mx_avg    TB_My_avg  \\\n",
              "0    -22.250000   747.561872  200.666288   6708.717789  8861.885588   \n",
              "1     -4.771217  3556.031457  676.339081  16692.647572  6329.099515   \n",
              "\n",
              "     TT_Mz_avg    MS_Mz_avg     BR_Mx_avg     BR_My_avg  \n",
              "0   819.209904    63.457528   4253.317748  15006.726860  \n",
              "1  3746.460605  1354.995442  10409.290476  16289.414152  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "df = pd.read_excel('LoadsDataBase_6D_Set123_FiltMinMaxCrit.xlsx') # Average the values from Set1,Set2 and Set3.\n",
        "df.head(2)\n",
        "# 0 : TT_Mx_avg\n",
        "# 1 : TT_My_avg\n",
        "# 2 : TB_Mx_avg\n",
        "# 3 : TB_My_avg\n",
        "# 4 : MS_Mz_avg\n",
        "# 5 : BR_Mx_avg\n",
        "# 6 : BR_My_avg\n",
        "# 7 : TT-Mz_avg"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZH0BO0flyfqA"
      },
      "source": [
        "# ============================================================\n",
        "# ==========================Section 1 ==========================\n",
        "# ============================================================"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "T-MY4d6DyfqB"
      },
      "outputs": [],
      "source": [
        "X = df.iloc[:,2:8]\n",
        "y = df.iloc[:,8:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knODMe_pyfqC",
        "outputId": "62520fc5-af91-46b0-e86b-80ee4a6df0d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The filtered data set consits on: 7664 entries.\n",
            "A total of 6131 will be used for training and validation.\n",
            "A total of 1533 will be used for testing the final model.\n"
          ]
        }
      ],
      "source": [
        "# Test split:\n",
        "X, X_test, y, y_test = train_test_split(X,y, test_size = 0.2, shuffle = True,  random_state = 101)\n",
        "\n",
        "print(f'The filtered data set consits on: {len(df)} entries.')\n",
        "print(f'A total of {len(X)} will be used for training and validation.')\n",
        "print(f'A total of {len(X_test)} will be used for testing the final model.')\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YfSEPuNpyfqC"
      },
      "source": [
        "### From now on, \"X\" and \"y\" will be used for train-validate the model. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "l_G1tpeiyfqD"
      },
      "outputs": [],
      "source": [
        "feature_range = (0, 1)\n",
        "scaler_x = preprocessing.MinMaxScaler(feature_range=feature_range).fit(X)\n",
        "X_scaled = scaler_x.transform(X)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL83yv4PyfqD"
      },
      "source": [
        "### Separte between train and validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "iCz1RrxTyfqD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1bb529f-e733-4809-fc4e-c978dd9baa05"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A total of 4904 for training, 64.0 % of total data\n",
            "A total of 1227 for validation, 16.0 % of total data\n",
            "A total of 1533 for testing, 20.0 % of total data\n"
          ]
        }
      ],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(X_scaled,y.values, test_size = 0.2, shuffle = True,  random_state = 101)\n",
        "\n",
        "# printing number of samples for train-validation-test\n",
        "print(f'A total of {y_train.shape[0]} for training, {round(100*y_train.shape[0]/len(df),1)} % of total data')\n",
        "print(f'A total of {y_val.shape[0]} for validation, {round(100*y_val.shape[0]/len(df),1)} % of total data')\n",
        "print(f'A total of {y_test.shape[0]} for testing, {round(100*y_test.shape[0]/len(df),1)} % of total data')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHAxUOKAyfqD"
      },
      "source": [
        "### The PyTorch worfklow can be summarized as follows:\n",
        "- 1) Design model (input, output size, forward pass)\n",
        "- 2) Construct loss and optimizer\n",
        "- 3) Training loop\n",
        "   - forward pass: compute prediction based on the current weights and biases of the net\n",
        "   - backward pass: compute the gradients of the loss function wrt. to model parameters\n",
        "   - update weigths in"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "VXRWKPCMyfqE"
      },
      "outputs": [],
      "source": [
        "input_size = 6             # np.shape(X_train)[1]\n",
        "output_channels = 8        # np.shape(y_train)[1]\n",
        "num_hid_1 = 50\n",
        "num_hid_2 = 50"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j7LZ5oF2yfqE"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_hid_1, num_hid_2):   \n",
        "        super(Net,self).__init__()  # inherit from the superclass Module\n",
        "        self.num_hid_1 = num_hid_1\n",
        "        self.num_hid_2 = num_hid_2\n",
        "        \n",
        "        self.fc1 = nn.Linear(in_features= input_size,\n",
        "                             out_features= self.num_hid_1,                             \n",
        "                            bias = True)  \n",
        "        \n",
        "        self.fc2 = nn.Linear(in_features = self.num_hid_1, \n",
        "                             out_features = self.num_hid_2,\n",
        "                            bias = True)\n",
        "        \n",
        "        self.fc3 = nn.Linear(in_features = self.num_hid_2, \n",
        "                             out_features = output_channels,\n",
        "                            bias = True)\n",
        "        \n",
        "#        self.dropout = nn.Dropout(p=0.15)\n",
        "        \n",
        "    def forward(self,x):\n",
        "        \n",
        "        out = self.fc1(x)  \n",
        "#        out = self.dropout(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc2(out)\n",
        "#        out = self.dropout(out)\n",
        "        out = F.relu(out)\n",
        "        out = self.fc3(out)                       #  torch.tanh(self.fc3(out))\n",
        "        \n",
        "        return out  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "hgoS_dl7yfqE"
      },
      "outputs": [],
      "source": [
        "# instantiate the class\n",
        "model = Net(num_hid_1,num_hid_2)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  model.to(device)\n",
        "\n",
        "# Define the loss function (mean square error)\n",
        "loss = nn.MSELoss()\n",
        "\n",
        "# Instantiate optimizer passing the net parameters as argument, and learning rate\n",
        "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
        "\n",
        "# list to store results\n",
        "train_losses , val_losses= [],[]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Try a dummy forward\n",
        "model(torch.tensor(X_train[0]).float().to(device))  # beware that need to convert from double to float"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5D2VJEGW1PYV",
        "outputId": "8cec047a-c5db-4fbb-8dfe-4f7db9041384"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 0.0802,  0.0496,  0.1292, -0.0897,  0.2109,  0.0153, -0.2685,  0.1344],\n",
              "       device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4PF3wIOHyfqF"
      },
      "source": [
        "# 2.1- Use the PyTorch DataLoader and Dataset utils.\n",
        "- DataLoader class combines a dataset and a sampler, and provides an iterable over the given dataset for training the model\n",
        "- Dataset: just an abstract class representing a :class:`Dataset`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "L_zMDOPmyfqF"
      },
      "outputs": [],
      "source": [
        "class FatigueLoads_TrainSet(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = X_train.shape[0]\n",
        "        self.x_data = torch.from_numpy(X_train) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(y_train) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples\n",
        "    \n",
        "class FatigueLoads_ValidationSet(Dataset):\n",
        "\n",
        "    def __init__(self):\n",
        "        self.n_samples = X_val.shape[0]\n",
        "        self.x_data = torch.from_numpy(X_val) # size [n_samples, n_features]\n",
        "        self.y_data = torch.from_numpy(y_val) # size [n_samples, 1]\n",
        "\n",
        "    # support indexing such that dataset[i] can be used to get i-th sample\n",
        "    def __getitem__(self, index):\n",
        "        return self.x_data[index], self.y_data[index]\n",
        "\n",
        "    # we can call len(dataset) to return the size\n",
        "    def __len__(self):\n",
        "        return self.n_samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wp0HiXkFyfqG"
      },
      "source": [
        "### Get first sample and unpack. Note that the enviromental inputs are normalized using MinMaxScaler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhNW8aG4yfqG",
        "outputId": "000cf010-9a07-4a9c-a15a-a0e02c923275"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.9213, 0.5395, 0.2971, 0.1574, 0.7369, 0.3075], dtype=torch.float64) tensor([ 7116.1376,   808.7441, 21966.9989, 16383.7768,  7347.3186,   807.4632,\n",
            "        18567.6736, 16935.8620], dtype=torch.float64)\n"
          ]
        }
      ],
      "source": [
        "train_dataset = FatigueLoads_TrainSet()\n",
        "valid_dataset = FatigueLoads_ValidationSet()\n",
        "\n",
        "first_data = train_dataset[0]\n",
        "features, loads = first_data\n",
        "print(features, loads)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJgJ7k7qyfqG",
        "outputId": "e5613941-b50f-4961-b30d-3246b7a61399"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num batches train: 38\n",
            "Num batches valid: 9\n"
          ]
        }
      ],
      "source": [
        "batch_size = 128\n",
        "num_epochs = 1200\n",
        "\n",
        "num_batches_train = X_train.shape[0] // batch_size\n",
        "num_batches_test = X_val.shape[0] // batch_size\n",
        "\n",
        "print(f'Num batches train: {num_batches_train}')\n",
        "print(f'Num batches valid: {num_batches_test}')\n",
        "train_loader = DataLoader(dataset=train_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)\n",
        "\n",
        "valid_loader = DataLoader(dataset=valid_dataset,\n",
        "                          batch_size=batch_size,\n",
        "                          shuffle=True,\n",
        "                          num_workers=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFDWLhA-yfqH"
      },
      "source": [
        "# 3.1- Start training loop "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_vrSR1SwyfqH",
        "outputId": "ab93ddaf-efb7-4126-884f-6f6b9875c3e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  0%|          | 2/1200 [00:00<04:27,  4.48it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1/1200 | Train loss: 183344096.0       | Val loss 200981456.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  1%|          | 11/1200 [00:02<03:11,  6.19it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 11/1200 | Train loss: 21691572.0       | Val loss 23628234.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  2%|▏         | 22/1200 [00:03<02:18,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 21/1200 | Train loss: 14754060.0       | Val loss 16034800.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  3%|▎         | 32/1200 [00:04<02:14,  8.68it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 31/1200 | Train loss: 14347904.0       | Val loss 15357517.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▎         | 42/1200 [00:05<02:11,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 41/1200 | Train loss: 14342269.0       | Val loss 15588164.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  4%|▍         | 52/1200 [00:07<02:12,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 51/1200 | Train loss: 14243185.0       | Val loss 15438265.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  5%|▌         | 62/1200 [00:08<02:05,  9.05it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 61/1200 | Train loss: 14072993.0       | Val loss 15147897.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  6%|▌         | 72/1200 [00:09<02:07,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 71/1200 | Train loss: 13790276.0       | Val loss 14895273.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  7%|▋         | 82/1200 [00:10<02:07,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 81/1200 | Train loss: 12936157.0       | Val loss 13821797.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 92/1200 [00:11<02:03,  8.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 91/1200 | Train loss: 7890234.0       | Val loss 8421719.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  8%|▊         | 102/1200 [00:12<02:06,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 101/1200 | Train loss: 5572696.5       | Val loss 5847793.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  9%|▉         | 112/1200 [00:13<02:03,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 111/1200 | Train loss: 4920043.5       | Val loss 5218136.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 10%|█         | 122/1200 [00:14<02:01,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 121/1200 | Train loss: 4668497.5       | Val loss 4922517.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 11%|█         | 132/1200 [00:16<01:59,  8.95it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 131/1200 | Train loss: 4517394.0       | Val loss 4774934.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 12%|█▏        | 142/1200 [00:17<01:58,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 141/1200 | Train loss: 4358824.0       | Val loss 4569163.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 13%|█▎        | 152/1200 [00:18<01:55,  9.07it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 151/1200 | Train loss: 4138121.75       | Val loss 4352541.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▎        | 162/1200 [00:19<01:56,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 161/1200 | Train loss: 3974760.75       | Val loss 4156221.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 14%|█▍        | 172/1200 [00:20<01:54,  8.96it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 171/1200 | Train loss: 3759154.25       | Val loss 4021233.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 15%|█▌        | 182/1200 [00:21<01:53,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 181/1200 | Train loss: 3599486.75       | Val loss 3780725.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 16%|█▌        | 192/1200 [00:22<01:56,  8.67it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 191/1200 | Train loss: 3476418.75       | Val loss 3691815.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 17%|█▋        | 202/1200 [00:24<01:53,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 201/1200 | Train loss: 3328114.5       | Val loss 3548609.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 212/1200 [00:25<01:53,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 211/1200 | Train loss: 3124941.25       | Val loss 3344186.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 18%|█▊        | 222/1200 [00:26<01:49,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 221/1200 | Train loss: 2829467.75       | Val loss 3012015.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 19%|█▉        | 232/1200 [00:27<01:49,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 231/1200 | Train loss: 2604452.0       | Val loss 2765103.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|██        | 242/1200 [00:28<01:47,  8.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 241/1200 | Train loss: 2590507.5       | Val loss 2665909.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 21%|██        | 252/1200 [00:29<01:51,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 251/1200 | Train loss: 2429007.25       | Val loss 2575312.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 22%|██▏       | 262/1200 [00:30<01:46,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 261/1200 | Train loss: 2335882.0       | Val loss 2519707.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 23%|██▎       | 272/1200 [00:31<01:44,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 271/1200 | Train loss: 2285966.75       | Val loss 2435569.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▎       | 282/1200 [00:33<01:45,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 281/1200 | Train loss: 2243919.75       | Val loss 2393204.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 24%|██▍       | 292/1200 [00:34<01:41,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 291/1200 | Train loss: 2166161.75       | Val loss 2315537.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 25%|██▌       | 302/1200 [00:35<01:41,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 301/1200 | Train loss: 2143347.5       | Val loss 2341409.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 26%|██▌       | 312/1200 [00:36<01:38,  9.04it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 311/1200 | Train loss: 2094695.75       | Val loss 2257115.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 27%|██▋       | 322/1200 [00:37<01:43,  8.49it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 321/1200 | Train loss: 2042833.875       | Val loss 2201438.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 332/1200 [00:38<01:40,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 331/1200 | Train loss: 1980184.875       | Val loss 2116706.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 28%|██▊       | 342/1200 [00:39<01:37,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 341/1200 | Train loss: 1919419.0       | Val loss 2074193.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 29%|██▉       | 352/1200 [00:41<01:34,  8.94it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 351/1200 | Train loss: 1824576.375       | Val loss 2022680.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 30%|███       | 362/1200 [00:42<01:35,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 361/1200 | Train loss: 1768969.875       | Val loss 1943562.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 31%|███       | 372/1200 [00:43<01:33,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 371/1200 | Train loss: 1705578.125       | Val loss 1849091.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 32%|███▏      | 382/1200 [00:44<01:35,  8.58it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 381/1200 | Train loss: 1631591.75       | Val loss 1797161.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 33%|███▎      | 392/1200 [00:45<01:32,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 391/1200 | Train loss: 1544495.75       | Val loss 1725113.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▎      | 402/1200 [00:46<01:31,  8.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 401/1200 | Train loss: 1489601.125       | Val loss 1677561.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 34%|███▍      | 412/1200 [00:48<01:28,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 411/1200 | Train loss: 1429083.125       | Val loss 1590393.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 35%|███▌      | 422/1200 [00:49<01:30,  8.60it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 421/1200 | Train loss: 1335583.0       | Val loss 1527484.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 36%|███▌      | 432/1200 [00:50<01:26,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 431/1200 | Train loss: 1281991.5       | Val loss 1436556.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 37%|███▋      | 442/1200 [00:51<01:25,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 441/1200 | Train loss: 1194788.75       | Val loss 1392836.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 452/1200 [00:52<01:25,  8.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 451/1200 | Train loss: 1169711.25       | Val loss 1307980.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 38%|███▊      | 462/1200 [00:53<01:24,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 461/1200 | Train loss: 1090488.0       | Val loss 1264165.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 39%|███▉      | 472/1200 [00:54<01:25,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 471/1200 | Train loss: 1056048.875       | Val loss 1245340.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 40%|████      | 482/1200 [00:56<01:21,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 481/1200 | Train loss: 1042018.625       | Val loss 1178625.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 41%|████      | 492/1200 [00:57<01:21,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 491/1200 | Train loss: 967282.4375       | Val loss 1134312.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 42%|████▏     | 502/1200 [00:58<01:18,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 501/1200 | Train loss: 971732.0       | Val loss 1121449.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 43%|████▎     | 512/1200 [00:59<01:19,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 511/1200 | Train loss: 917361.375       | Val loss 1077339.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▎     | 522/1200 [01:00<01:17,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 521/1200 | Train loss: 920708.3125       | Val loss 1091219.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 44%|████▍     | 532/1200 [01:01<01:17,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 531/1200 | Train loss: 896200.0       | Val loss 1049052.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 45%|████▌     | 542/1200 [01:02<01:16,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 541/1200 | Train loss: 885439.5625       | Val loss 1027369.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 46%|████▌     | 552/1200 [01:04<01:12,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 551/1200 | Train loss: 848926.875       | Val loss 1001893.3125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 47%|████▋     | 562/1200 [01:05<01:30,  7.08it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 561/1200 | Train loss: 849574.6875       | Val loss 999059.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 572/1200 [01:06<01:11,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 571/1200 | Train loss: 832547.5       | Val loss 974960.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 48%|████▊     | 582/1200 [01:07<01:10,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 581/1200 | Train loss: 820244.75       | Val loss 956063.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 49%|████▉     | 592/1200 [01:08<01:09,  8.73it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 591/1200 | Train loss: 814060.1875       | Val loss 965453.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 50%|█████     | 602/1200 [01:09<01:11,  8.41it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 601/1200 | Train loss: 800081.9375       | Val loss 941013.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 51%|█████     | 612/1200 [01:11<01:07,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 611/1200 | Train loss: 796306.0       | Val loss 929236.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 52%|█████▏    | 622/1200 [01:12<01:06,  8.72it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 621/1200 | Train loss: 782147.75       | Val loss 943975.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 53%|█████▎    | 632/1200 [01:13<01:04,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 631/1200 | Train loss: 775605.75       | Val loss 899529.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▎    | 642/1200 [01:14<01:03,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 641/1200 | Train loss: 759320.875       | Val loss 896551.1875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 54%|█████▍    | 652/1200 [01:15<01:02,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 651/1200 | Train loss: 769391.75       | Val loss 919507.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 55%|█████▌    | 662/1200 [01:16<01:02,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 661/1200 | Train loss: 743120.5       | Val loss 864050.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 56%|█████▌    | 672/1200 [01:17<01:00,  8.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 671/1200 | Train loss: 744633.8125       | Val loss 907012.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 57%|█████▋    | 682/1200 [01:19<01:00,  8.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 681/1200 | Train loss: 734255.4375       | Val loss 879072.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 692/1200 [01:20<00:57,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 691/1200 | Train loss: 721852.375       | Val loss 852799.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 58%|█████▊    | 702/1200 [01:21<00:56,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 701/1200 | Train loss: 717062.875       | Val loss 839743.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 59%|█████▉    | 712/1200 [01:22<00:55,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 711/1200 | Train loss: 711000.1875       | Val loss 843328.9375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 60%|██████    | 722/1200 [01:23<00:54,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 721/1200 | Train loss: 724916.25       | Val loss 858371.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 61%|██████    | 732/1200 [01:24<00:52,  8.85it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 731/1200 | Train loss: 697369.9375       | Val loss 850275.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 62%|██████▏   | 742/1200 [01:25<00:53,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 741/1200 | Train loss: 692153.3125       | Val loss 825663.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 63%|██████▎   | 752/1200 [01:27<00:52,  8.54it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 751/1200 | Train loss: 695308.1875       | Val loss 820642.1875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▎   | 762/1200 [01:28<00:50,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 761/1200 | Train loss: 682278.4375       | Val loss 835776.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 64%|██████▍   | 772/1200 [01:29<00:49,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 771/1200 | Train loss: 738175.125       | Val loss 919795.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 65%|██████▌   | 782/1200 [01:30<00:48,  8.65it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 781/1200 | Train loss: 697633.4375       | Val loss 830232.4375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 66%|██████▌   | 792/1200 [01:31<00:46,  8.82it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 791/1200 | Train loss: 689082.625       | Val loss 836867.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 67%|██████▋   | 802/1200 [01:32<00:45,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 801/1200 | Train loss: 675444.875       | Val loss 797338.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 812/1200 [01:34<00:45,  8.47it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 811/1200 | Train loss: 667778.625       | Val loss 824824.3125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 68%|██████▊   | 822/1200 [01:35<00:43,  8.61it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 821/1200 | Train loss: 673424.9375       | Val loss 825607.6875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 69%|██████▉   | 832/1200 [01:36<00:42,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 831/1200 | Train loss: 649572.0625       | Val loss 795988.3125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 70%|███████   | 842/1200 [01:37<00:41,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 841/1200 | Train loss: 667296.5625       | Val loss 806080.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 71%|███████   | 852/1200 [01:38<00:40,  8.64it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 851/1200 | Train loss: 645459.75       | Val loss 792479.3125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 862/1200 [01:39<00:38,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 861/1200 | Train loss: 639916.1875       | Val loss 814340.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 73%|███████▎  | 872/1200 [01:41<00:38,  8.53it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 871/1200 | Train loss: 633917.4375       | Val loss 809683.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▎  | 882/1200 [01:42<00:37,  8.52it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 881/1200 | Train loss: 642381.9375       | Val loss 803518.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 74%|███████▍  | 892/1200 [01:43<00:36,  8.55it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 891/1200 | Train loss: 633518.3125       | Val loss 778568.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 75%|███████▌  | 902/1200 [01:44<00:34,  8.76it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 901/1200 | Train loss: 624610.375       | Val loss 782469.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 76%|███████▌  | 912/1200 [01:45<00:32,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 911/1200 | Train loss: 642279.0       | Val loss 808182.4375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 77%|███████▋  | 922/1200 [01:46<00:31,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 921/1200 | Train loss: 628725.25       | Val loss 780524.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 932/1200 [01:47<00:30,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 931/1200 | Train loss: 612710.5625       | Val loss 760493.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 78%|███████▊  | 942/1200 [01:49<00:30,  8.50it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 941/1200 | Train loss: 626098.875       | Val loss 791759.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 79%|███████▉  | 952/1200 [01:50<00:27,  8.90it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 951/1200 | Train loss: 603750.625       | Val loss 738049.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 80%|████████  | 962/1200 [01:51<00:27,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 961/1200 | Train loss: 609054.8125       | Val loss 766822.3125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 81%|████████  | 972/1200 [01:52<00:26,  8.75it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 971/1200 | Train loss: 598981.1875       | Val loss 750943.0625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 82%|████████▏ | 982/1200 [01:53<00:24,  8.88it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 981/1200 | Train loss: 606098.1875       | Val loss 748732.875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 83%|████████▎ | 992/1200 [01:54<00:23,  8.77it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 991/1200 | Train loss: 607878.75       | Val loss 757335.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▎ | 1002/1200 [01:55<00:22,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1001/1200 | Train loss: 594244.875       | Val loss 751489.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 84%|████████▍ | 1012/1200 [01:57<00:21,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1011/1200 | Train loss: 587730.1875       | Val loss 758386.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 85%|████████▌ | 1022/1200 [01:58<00:19,  8.92it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1021/1200 | Train loss: 596867.1875       | Val loss 766962.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 86%|████████▌ | 1032/1200 [01:59<00:19,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1031/1200 | Train loss: 594899.25       | Val loss 764122.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 87%|████████▋ | 1042/1200 [02:00<00:17,  8.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1041/1200 | Train loss: 612338.875       | Val loss 748861.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1052/1200 [02:01<00:17,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1051/1200 | Train loss: 601244.8125       | Val loss 734139.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 88%|████████▊ | 1062/1200 [02:02<00:15,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1061/1200 | Train loss: 599836.6875       | Val loss 743073.6875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 89%|████████▉ | 1072/1200 [02:03<00:14,  8.78it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1071/1200 | Train loss: 574335.1875       | Val loss 712773.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 1082/1200 [02:05<00:13,  8.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1081/1200 | Train loss: 588348.125       | Val loss 719874.75\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 91%|█████████ | 1092/1200 [02:06<00:12,  8.87it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1091/1200 | Train loss: 572699.0       | Val loss 706968.125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 92%|█████████▏| 1102/1200 [02:07<00:11,  8.89it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1101/1200 | Train loss: 578210.125       | Val loss 715843.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 93%|█████████▎| 1112/1200 [02:08<00:10,  8.79it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1111/1200 | Train loss: 560747.875       | Val loss 705050.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▎| 1122/1200 [02:09<00:08,  8.86it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1121/1200 | Train loss: 558368.375       | Val loss 725324.375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 94%|█████████▍| 1132/1200 [02:10<00:07,  8.56it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1131/1200 | Train loss: 573041.375       | Val loss 755063.6875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 95%|█████████▌| 1142/1200 [02:11<00:06,  8.69it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1141/1200 | Train loss: 570077.25       | Val loss 704713.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 96%|█████████▌| 1152/1200 [02:12<00:05,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1151/1200 | Train loss: 543715.4375       | Val loss 715317.8125\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 97%|█████████▋| 1162/1200 [02:14<00:04,  8.71it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1161/1200 | Train loss: 563326.1875       | Val loss 724384.25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 1172/1200 [02:15<00:03,  8.83it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1171/1200 | Train loss: 543687.25       | Val loss 707142.5625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 98%|█████████▊| 1182/1200 [02:16<00:02,  8.70it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1181/1200 | Train loss: 562347.0       | Val loss 722683.4375\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 1192/1200 [02:17<00:00,  8.74it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1191/1200 | Train loss: 543934.1875       | Val loss 700950.5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1200/1200 [02:18<00:00,  8.66it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 2min 14s, sys: 2.6 s, total: 2min 17s\n",
            "Wall time: 2min 18s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "for epoch in tqdm(range(num_epochs)):\n",
        "    \n",
        "    epoch_loss = 0\n",
        "    model.train()\n",
        "    \n",
        "    for i, (inputs, loads) in enumerate(train_loader):\n",
        "        #print(features, loads)\n",
        "        \n",
        "        optimizer.zero_grad()                      # zeroize accumulated gradients in parameters             \n",
        "        \n",
        "        output = model(inputs.float().to(device))             # forwards pass       \n",
        "        batch_loss = loss(output, loads.float().to(device))   # compute loss for current batch\n",
        "        \n",
        "        batch_loss.backward()                      # compute the gradient of the loss wrt. model parameters\n",
        "        optimizer.step()                           # update weights according to the comptued gradients\n",
        "        \n",
        "    \n",
        "    epoch_loss_train = 0\n",
        "    epoch_loss_test = 0\n",
        "    model.eval()\n",
        "    \n",
        "    ##### Evaluate training\n",
        "    for i, (inputs, loads) in enumerate(train_loader):\n",
        "        \n",
        "        output = model(inputs.float().to(device))\n",
        "        \n",
        "        batch_loss_train = loss(output, loads.float().to(device))  # compute loss for the current batch\n",
        "        epoch_loss_train += batch_loss_train            # accumulate loss for the current epoch\n",
        "        \n",
        "        #print(f'Epoch: {epoch+1}/{num_epochs}  | Step {i+1}/{n_iterations}')\n",
        "    \n",
        "    ##### Evaluate validation    \n",
        "    for i, (inputs, loads) in enumerate(valid_loader):\n",
        "        \n",
        "        output = model(inputs.float().to(device))\n",
        "        \n",
        "        batch_loss_test = loss(output, loads.float().to(device))  # compute loss for the current batch\n",
        "        epoch_loss_test += batch_loss_test     # accumulate loss for the current epoch\n",
        "        \n",
        "        #print(f'Epoch: {epoch+1}/{num_epochs}  | Step {i+1}/{n_iterations}')\n",
        "    \n",
        "    if epoch % 10 == 0: \n",
        "        print(f'Epoch: {epoch+1}/{num_epochs} | Train loss: {epoch_loss_train/num_batches_train}       | Val loss {epoch_loss_test/num_batches_test}')\n",
        "        \n",
        "    # store in list for plotting the loss per epoch    \n",
        "    val_losses.append(epoch_loss_test.cpu().detach().numpy()/num_batches_test)  \n",
        "    train_losses.append(epoch_loss_train.cpu().detach().numpy()/num_batches_train)  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "T_hQS6-NyfqH",
        "outputId": "e48ddc9f-0936-41e1-c9c1-619e51f8e16c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f5f34fe4790>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "plt.figure(figsize = (8,6))\n",
        "plt.plot(train_losses[50:])\n",
        "plt.plot(val_losses[50:], '-k')\n",
        "plt.title('Training-Validation loss', fontsize = 16)\n",
        "plt.grid()\n",
        "plt.legend(['Training loss','Validation loss'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "svHqwvNnyfqH"
      },
      "source": [
        "# Evalute on the test data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRJxj45YyfqI"
      },
      "source": [
        "### Scale the test data before evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VL3rv5n4yfqI"
      },
      "outputs": [],
      "source": [
        "Test_scaler_x = preprocessing.MinMaxScaler(feature_range=feature_range).fit(X_test) # maybe try another for X?\n",
        "X_Test_scaled = Test_scaler_x.transform(X_test)\n",
        "\n",
        "predictions = model(torch.tensor(X_Test_scaled).float().to(device)).cpu().detach().numpy()\n",
        "test_targets = y_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Re20qSYlyfqI"
      },
      "outputs": [],
      "source": [
        "for idx, ch in enumerate(df.columns.tolist()[8:]):\n",
        "  # issues with 2 and 7\n",
        "    plt.figure(idx, figsize = (8,6))\n",
        "    sns.scatterplot(x = predictions[:,idx], y = test_targets[:,idx])\n",
        "    plt.title(f'DELs: {ch}', fontsize = 20)\n",
        "    plt.xlabel('Predictions [kNm]', fontsize = 12)\n",
        "    plt.ylabel('Targets [kNm]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sp42xds3yfqI"
      },
      "outputs": [],
      "source": [
        "mse_list = []\n",
        "r2_score_list = []\n",
        "for i in range(len(df.columns.tolist()[8:])):\n",
        "    #print(f'MSE {AllTargetData.columns[i]} Channel : \\n {mean_squared_error(AllTargetData.values[:,i], Yout[:,i])}')\n",
        "    mse_list.append(mean_squared_error(test_targets[:,i], predictions[:,i]))\n",
        "    r2_score_list.append(r2_score(test_targets[:,i], predictions[:,i]))\n",
        " \n",
        "\n",
        " # Compute the normalized mean square error:\n",
        "Norm_RMSE = np.sqrt(np.array(mse_list)) / y_test.describe().loc['mean'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6fV2w0tuyfqI"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize= (10,4)) \n",
        "sns.barplot(x= df.columns.tolist()[8:], y= r2_score_list) \n",
        "plt.ylim([min(r2_score_list)*0.92,max(r2_score_list)*1.02])\n",
        "plt.ylabel('R2 score', fontsize = 20)\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4ahdNuXtyfqL"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize= (10,4)) \n",
        "sns.barplot(x= df.columns.tolist()[8:], y= Norm_RMSE) \n",
        "plt.ylim([0,max(Norm_RMSE)*1.02])\n",
        "plt.ylabel('Normalized Root Mean Square Error', fontsize = 20)\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNcnqbI0yfqL"
      },
      "source": [
        "# ============================================================\n",
        "# ==========================Section 2 ==========================\n",
        "# ============================================================\n",
        "### Compare versus the wind2loads neural net"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWf4JomiyfqL"
      },
      "outputs": [],
      "source": [
        "error on purpose"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_8aInrbyfqL"
      },
      "outputs": [],
      "source": [
        "from w2l import neuralnets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OX4GZfZsyfqM"
      },
      "outputs": [],
      "source": [
        "# define the model using the same net architecture, and train for the same number of epochs using the previously batch size as well.\n",
        "w2l_net = neuralnets.ann(layersizes = [input_size, num_hid_1, num_hid_2, output_channels],\n",
        "                       params = {'minibatchsize':64, 'nepochs':500}, \n",
        "                       output_style = 'None',\n",
        "                        testratios = [0.7, 0.3, 0.])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1IbgAiXyfqM"
      },
      "outputs": [],
      "source": [
        "# train using the data from the first split\n",
        "Outdata = w2l_net.train(X.values,y.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6eSGa8Q4yfqM"
      },
      "outputs": [],
      "source": [
        "w2l_net.params"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ogfaiilyfqM"
      },
      "outputs": [],
      "source": [
        "Outdata.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BQtaJ7qjyfqM"
      },
      "source": [
        "$\\color{red}{\\text{Why 500 epochs tho}}$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o-y11L6myfqM"
      },
      "outputs": [],
      "source": [
        "plt.plot(Outdata['Jhist'][50:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qNhYctQYyfqM"
      },
      "outputs": [],
      "source": [
        "Yout = w2l_net.predict(X_test.values) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qe75yfjwyfqN"
      },
      "outputs": [],
      "source": [
        "for idx, ch in enumerate(df.columns.tolist()[8:]):\n",
        "  # issues with 2 and 7\n",
        "    plt.figure(idx, figsize = (8,6))\n",
        "    sns.scatterplot(Yout[:,idx],test_targets[:,idx])\n",
        "    sns.scatterplot(predictions[:,idx],test_targets[:,idx])\n",
        "    plt.title(f'DELs: {ch}', fontsize = 20)\n",
        "    plt.legend(['W2L','PyTorch'])\n",
        "    plt.xlabel('Predictions [kNm]', fontsize = 12)\n",
        "    plt.ylabel('Targets [kNm]')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91DYU0rpyfqN"
      },
      "outputs": [],
      "source": [
        "W2L_mse_list = []\n",
        "W2L_r2_score_list = []\n",
        "for i in range(len(df.columns.tolist()[8:])):\n",
        "    #print(f'MSE {AllTargetData.columns[i]} Channel : \\n {mean_squared_error(AllTargetData.values[:,i], Yout[:,i])}')\n",
        "    W2L_mse_list.append(mean_squared_error(test_targets[:,i], Yout[:,i]))\n",
        "    W2L_r2_score_list.append(r2_score(test_targets[:,i], Yout[:,i]))\n",
        "    \n",
        "W2L_Norm_RMSE = np.sqrt(np.array(W2L_mse_list)) / y_test.describe().loc['mean'].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNPY0-5RyfqN"
      },
      "outputs": [],
      "source": [
        "fig = plt.figure(figsize= (12,6)) \n",
        "sns.barplot(x= df.columns.tolist()[8:], y= W2L_r2_score_list) \n",
        "plt.ylim([min(W2L_r2_score_list)*0.92,max(W2L_r2_score_list)*1.02])\n",
        "plt.ylabel('R2 score', fontsize = 20)\n",
        "plt.grid()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPUUbRvHyfqN"
      },
      "source": [
        "# Compare Wind2Loads net versus PyTorch implementation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OCUCMseEyfqN"
      },
      "outputs": [],
      "source": [
        "barplot_lst = []\n",
        "for i,ch in enumerate(df.columns.tolist()[8:]):\n",
        "    barplot_lst.append(['pytorch',ch,r2_score_list[i]])\n",
        "for i,ch in enumerate(df.columns.tolist()[8:]):\n",
        "    barplot_lst.append(['W2L',ch,W2L_r2_score_list[i]])  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HqSYNR6MyfqN"
      },
      "outputs": [],
      "source": [
        "df_comparison = pd.DataFrame(barplot_lst,\n",
        "                  columns=['Model','channel','r2'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1sKDnNqGyfqN"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "df_comparison.pivot(\"channel\", \"Model\", \"r2\").plot(kind='bar')\n",
        "plt.ylim([min(r2_score_list)*0.98,max(r2_score_list)*1.02])\n",
        "plt.title('R2', fontsize = 18)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrEdplLzyfqN"
      },
      "outputs": [],
      "source": [
        "barplot_lst_NMSE = []\n",
        "for i,ch in enumerate(df.columns.tolist()[8:]):\n",
        "    barplot_lst_NMSE.append(['pytorch',ch , Norm_RMSE[i]])\n",
        "for i,ch in enumerate(df.columns.tolist()[8:]):\n",
        "    barplot_lst_NMSE.append(['W2L', ch, W2L_Norm_RMSE[i]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oK2juOOmyfqO"
      },
      "outputs": [],
      "source": [
        "df_NRMSE_comparison = pd.DataFrame(barplot_lst_NMSE,\n",
        "                  columns=['Model','channel','NRMSE'])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aOqwYSSSyfqO"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,6))\n",
        "df_NRMSE_comparison.pivot(\"channel\", \"Model\", \"NRMSE\").plot(kind='bar')\n",
        "plt.ylim([0,max(W2L_Norm_RMSE)*1.02])\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "colab": {
      "name": "PyTorch_Model_GPU.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}